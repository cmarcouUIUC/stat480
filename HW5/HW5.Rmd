---
title: "Homework 5 Assignment"
author: "Charlie Marcou, Carrie Mecca, Jasmine Zhang, and Jessie Bustin"
fontsize: 10 pt
output: 
    pdf_document:
        fig_width: 6
        fig_height: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      #include = TRUE, 
                      fig.width = 6, fig.height = 4,
                      warning = FALSE,
                      message = FALSE,
                      cache = TRUE,
                      digits = 3,
                      width = 48) 
```

We will use congress109 data in package textir. It counts for 1,000 phrases used by each of 529 members of the 109th US congress.
```{r}
library(textir) # to get the data

library(maptpx) # for the topics function

data(congress109) # load the data
```

The counts are in congress109counts. We also have congress109Ideology, a data.frame containing some information about each speaker. These includes some partisan metrics"

party (Republican, Democrat, or Independent)
repshare: share of constituents voting for Bush in 2004.
Common Scores [cs1,cs2]: basically, the first two principal components of roll-call votes (next week!).

## 1. Fit K-means to speech text for K in 5,10,15,20,25. Use an IC to choose the K and interpret the selected model.

Both agree on 5 as the optimal number of clusters.

```{r}
xcongress <- scale(as.matrix( congress109Counts/rowSums(congress109Counts) )) #do we need to do this or just scale?
#xcongress <- scale(congress109Counts)

k_list <-5*(1:5)
kfit <- lapply(k_list, function(k) kmeans(xcongress,k))

source("kIC.R") ## utility script
kaicc <- sapply(kfit,kIC)
kbic <- sapply(kfit,kIC,"B")

## plot 'em
plot(y=kaicc, x=k_list, xlab="K", ylab="IC", 
	ylim=range(c(kaicc,kbic)),
	bty="n", type="l", lwd=2)

abline(v=k_list[which.min(kaicc)], col=4)
abline(v=k_list[which.min(kbic)],col=3)

paste0('AIC Optimal k: ', k_list[which.min(kaicc)])
paste0('BIC Optimal k: ',k_list[which.min(kbic)])
```
#i think this works charlie? she didn't account for the index and actual k value in the list not being the same...

```{r}
##things look weird below, mostly copying from wine.r here, but might be goofing something.


#normalize by length
fs <- scale(as.matrix( congress109Counts/rowSums(congress109Counts) ))

kfit <- lapply(5*(1:5), function(k) kmeans(fs,k))

# choose number of clusters?

source("kIC.R") ## utility script

# you give it kmeans fit, 
# then "A" for AICc (default) or "B" for BIC

kaicc <- sapply(kfit,kIC)

kbic <- sapply(kfit,kIC,"B")

## plot 'em

plot(kaicc, xlab="K", ylab="IC", 
	ylim=range(c(kaicc,kbic)), # get them on same page
	bty="n", type="l", lwd=2)

abline(v=which.min(kaicc))

lines(kbic, col=4, lwd=2)

abline(v=which.min(kbic),col=4)


```


## 2. Fit a topic model for the speech counts. Use Bayes factors to choose the number of topics, and interpret your chosen model.

```{r}
##Basically, I have just pasted in all her stuff, here, will need to check what # of topics to choose later.

## topic modelling.  Treat counts as actual counts!
## i.e., model them with a multinomial
## we'll use the topics function in maptpx (there are other options out there)

## you need to convert from a Matrix to a `slam' simple_triplet_matrix
## luckily, this is easy.

x <- as.simple_triplet_matrix(congress109Counts)

# to fit, just give it the counts, number of `topics' K, and any other args

tpc <- topics(x,K=10) 


dim(tpc$theta)
colSums(tpc$theta)

dim(tpc$omega)
rowSums(tpc$omega)

## choosing the number of topics
## If you supply a vector of topic sizes, it uses a Bayes factor to choose
## (BF is like exp(-BIC), so you choose the bigggest BF)
## the algo stops if BF drops twice in a row

tpcs <- topics(x,K=5*(1:5), verb=10) # it chooses 10 topics 

## interpretation
# summary prints the top `n' words for each topic,
# under ordering by `topic over aggregate' lift:
#    the topic word prob over marginal word prob.

summary(tpcs, n=10) 

# this will promote rare words that with high in-topic prob

# alternatively, you can look at words ordered by simple in-topic prob
## the topic-term probability matrix is called 'theta', 
## and each column is a topic
## we can use these to rank terms by probability within topics

rownames(tpcs$theta)[order(tpcs$theta[,1], decreasing=TRUE)[1:10]]

rownames(tpcs$theta)[order(tpcs$theta[,2], decreasing=TRUE)[1:10]]
```


## 3.  Connect the unsupervised clusters to partisanship.

```{r}

```


I tabulate party membership by K-means cluster. Are there any non-partisan topics?
I fit topic regressions for each of party and repshare. Compare to regression onto phrase percentages:
x<-100*congress109Counts/rowSums(congress109Counts)
