---
title: "480 Project"
author: "Charlie Marcou, Carrie Mecca"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
drugsComTrain_raw <- read_delim("drugsComTrain_raw.tsv", delim = "\t", escape_double = FALSE,  trim_ws = TRUE)
```

```{r}
library(tm)
dtm <- DocumentTermMatrix(drugsComTrain_raw$review,
                          control = list(stopwords = TRUE, 
                                         removeNumbers = TRUE,
                                         removePunctuation = TRUE,
                                         stemming = TRUE))
dtm <- removeSparseTerms(dtm,0.995) #remove infrequent terms
rowTotals <- apply(dtm , 1, sum) #Find the sum of words in each Document
dtm.new   <- dtm[rowTotals> 0, ]           #remove all docs without words

```

```{r}
#look at matrix
head(dtm.new)
inspect(dtm.new[1:5, 1000:1005])
```

```{r}
#topic modeling
library(maptpx)
x <- as.simple_triplet_matrix(dtm.new)

tpcs <- topics(x,K=c(5,10), verb=10) #try multiple Ks
dim(tpc$theta)
colSums(tpc$theta)

summary(tpcs, n=10) #prints top 10 words per document
```

```{r}
library(wordcloud)
color_palette <- colors=brewer.pal(8, "Dark2") #however many need based on k picked

for (i in 1:10) {
wordcloud(row.names(tpcs$theta), 
	freq=tpcs$theta[,i], min.freq=0.004, col=color_palette[i])
}
```



```{r clustering}
xdtm<-scale(dtm.new)
k_list <-(1:20)
kfit <- lapply(k_list, function(k) kmeans(xdtm,k))

source("kIC.R") ## utility script
kaicc <- sapply(kfit,kIC)
kbic <- sapply(kfit,kIC,"B")

## plot 'em
plot(y=kaicc, x=k_list, xlab="K", ylab="IC", 
	ylim=range(c(kaicc,kbic)),
	bty="n", type="l", lwd=2)
lines(y=kbic, x=k_list, xlab="K", ylab="IC", 
	ylim=range(c(kaicc,kbic)),
	bty="n", type="l", lwd=2, col='red')

abline(v=k_list[which.min(kaicc)], col=4)
abline(v=k_list[which.min(kbic)],col=3)

paste0('AIC Optimal k: ', k_list[which.min(kaicc)])
paste0('BIC Optimal k: ',k_list[which.min(kbic)])


##Get r^2
k_index= k_list[which.min(kaicc)]
paste0('R^2: ',1 - sum(kfit[[k_index]]$tot.withinss)/kfit[[k_index]]$totss)
```

```{r}
unique(drugsComTrain_raw$rating)

drugsComTrain_raw$rating_group <-ifelse(drugsComTrain_raw$rating>=8,1,0)
library(dplyr)
drugsComTrain_raw %>%count(rating_group)
```

```{r}
library(gamlr)
x.words <- 100*as.matrix(dtm.new)/rowSums(as.matrix(dtm.new))
train <- drugsComTrain_raw[rowTotals> 0, ] #remove empty docs
xclust <- sparse.model.matrix(~factor(kfit[[k]]$cluster)+##wine$color) # cluster membership matrix

##regress words vs rating
regwords.cv <- cv.gamlr(x.words, train$rating_group, family="binomial")
ratingreg <- gamlr(tpcs_5$omega, train$rating_group, family="binomial") #topic regression
ratingregclust <- cv.gamlr(xclust,train$rating_group,lambda.min.ratio=1e-5,family="binomial")

##regress words vs useful count
regwords.cv.2 <- cv.gamlr(x.words, train$usefulCount)
usefulreg <- gamlr(tpcs$omega, train$usefulCount) #topic regression
usefulregclust <- cv.gamlr(xclust,train$usefulCount,lambda.min.ratio=1e-5)

```



step 1 is to probably create word matrix

ok some ideas
--build topic model and or cluster words
--predict rating / review usefulness from words/bigrams/phrases
--if we do do a prediction compare straight glm/fdr analysis with lasso
--perhaps do a double lasso controlling for other variables like date/condition/review/usefulness.

